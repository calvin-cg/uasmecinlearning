{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "#import config\n",
    "#import data\n",
    "#import model\n",
    "import datetime\n",
    "#import neural_network\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIRECTORY INFORMATION\n",
    "# DATASET = \"Dogs\"\n",
    "ROOT_DIR = os.path.abspath('../')\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'Dataset/')\n",
    "OUT_DIR = os.path.join(ROOT_DIR, 'Result/')\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, 'Model/')\n",
    "LOG_DIR = os.path.join(ROOT_DIR, 'Logs/')\n",
    "\n",
    "TRAIN_DIR = \"train/ab1.npy\"\n",
    "TEST_DIR = \"test/gray_scale.npy\"\n",
    "\n",
    "# DATA INFORMATION\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# RANDOM NUMBER GENERATOR INFORMATION\n",
    "SEED = 128\n",
    "\n",
    "# TRAINING INFORMATION\n",
    "USE_PRETRAINED = False\n",
    "PRETRAINED = \"Dogsmodel1_100\"\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "dirname = os.path.join(ROOT_DIR, 'Dataset2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATA():\n",
    "\n",
    "    def __init__(self, dirname):\n",
    "        self.dir_path = os.path.join(DATA_DIR, dirname)\n",
    "        self.filelist = os.listdir(self.dir_path)\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.size = len(self.filelist)\n",
    "        self.data_index = 0\n",
    "\n",
    "    def read_img(self, filename):\n",
    "        img = cv2.imread(filename, 3)\n",
    "        height, width, channels = img.shape\n",
    "        labimg = cv2.cvtColor(cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE)), cv2.COLOR_BGR2Lab)\n",
    "        return np.reshape(labimg[:,:,0], (IMAGE_SIZE, IMAGE_SIZE, 1)), labimg[:, :, 1:]\n",
    "\n",
    "    def generate_batch(self):\n",
    "        batch = []\n",
    "        labels = []\n",
    "        filelist = []\n",
    "        for i in range(self.batch_size):\n",
    "            filename = os.path.join(DATA_DIR, self.dir_path, self.filelist[self.data_index])\n",
    "            filelist.append(self.filelist[self.data_index])\n",
    "            greyimg, colorimg = self.read_img(filename)\n",
    "            batch.append(greyimg)\n",
    "            labels.append(colorimg)\n",
    "            self.data_index = (self.data_index + 1) % self.size\n",
    "        batch = np.asarray(batch)/255\n",
    "        labels = np.asarray(labels)/255\n",
    "        return batch, labels, filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "\n",
    "    def __init__(self, shape, stddev, value):\n",
    "        self.weights = tf.Variable(tf.truncated_normal(shape=shape, stddev=stddev))\n",
    "        self.biases = tf.Variable(tf.constant(value=value, shape=[shape[-1]]))\n",
    "\n",
    "    def feed_forward(self, input_data, stride=None):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution_Layer(Layer):\n",
    "\n",
    "    def __init__(self, shape, stddev, value):\n",
    "        super(Convolution_Layer, self).__init__(shape, stddev, value)\n",
    "\n",
    "    def feed_forward(self, input_data, stride):\n",
    "        conv = tf.nn.conv2d(input_data, self.weights, stride, padding=\"SAME\")\n",
    "        output_data = tf.nn.tanh(tf.nn.bias_add(conv, self.biases))\n",
    "        return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected_Layer(Layer):\n",
    "\n",
    "    def __init__(self, shape, stddev, value):\n",
    "        super(FullyConnected_Layer, self).__init__(shape, stddev, value)\n",
    "\n",
    "    def feed_forward(self, input_data, stride=None):\n",
    "        fullyconnected = tf.matmul(input_data, self.weights)\n",
    "        output_data = tf.nn.relu(tf.nn.bias_add(fullyconnected, self.biases))\n",
    "        return output_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fusion_Layer(Convolution_Layer):\n",
    "\n",
    "    def __init__(self, shape, stddev, value):\n",
    "        super(Fusion_Layer, self).__init__(shape, stddev, value)\n",
    "\n",
    "    def feed_forward(self, mid_features, global_features, stride):\n",
    "        mid_features_shape = mid_features.get_shape().as_list()\n",
    "        mid_features_reshaped = tf.reshape(mid_features, [BATCH_SIZE, mid_features_shape[1]*mid_features_shape[2], 256])\n",
    "        fusion_level = []\n",
    "        for j in range(mid_features_reshaped.shape[0]):\n",
    "            for i in range(mid_features_reshaped.shape[1]):\n",
    "                see_mid = mid_features_reshaped[j, i, :]\n",
    "                see_mid_shape = see_mid.get_shape().as_list()\n",
    "                see_mid = tf.reshape(see_mid, [1, see_mid_shape[0]])\n",
    "                global_features_shape = global_features[j, :].get_shape().as_list()\n",
    "                see_global = tf.reshape(global_features[j, :], [1, global_features_shape[0]])\n",
    "                fusion = tf.concat([see_mid, see_global], 1)\n",
    "                fusion_level.append(fusion)\n",
    "        fusion_level = tf.stack(fusion_level, 1)\n",
    "        fusion_level = tf.reshape(fusion_level, [BATCH_SIZE, 28, 28, 512])\n",
    "        return super(Fusion_Layer, self).feed_forward(fusion_level, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output_Layer(Layer):\n",
    "\n",
    "    def __init__(self, shape, stddev, value):\n",
    "        super(Output_Layer, self).__init__(shape, stddev, value)\n",
    "\n",
    "    def feed_forward(self, input_data, stride):\n",
    "        conv = tf.nn.conv2d(input_data, self.weights, stride, padding='SAME')\n",
    "        output_data = tf.nn.sigmoid(tf.nn.bias_add(conv, self.biases))\n",
    "        return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess(imgs):\n",
    "    imgs = imgs * 255\n",
    "    imgs[imgs > 255] = 255\n",
    "    imgs[imgs < 0] = 0\n",
    "    return imgs.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(batchX, predictedY, filelist):\n",
    "    for i in range(BATCH_SIZE):\n",
    "        result = np.concatenate((batchX[i], predictedY[i]), axis=2)\n",
    "        result = cv2.cvtColor(result, cv2.COLOR_Lab2BGR)\n",
    "        save_path = os.path.join(OUT_DIR, filelist[i][:-4] + \"reconstructed.jpg\")\n",
    "        cv2.imwrite(save_path, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MODEL():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.inputs = tf.placeholder(shape=[BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 1], dtype=tf.float32)\n",
    "        self.labels = tf.placeholder(shape=[BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 2], dtype=tf.float32)\n",
    "        self.loss = None\n",
    "        self.output = None\n",
    "\n",
    "    def build(self):\n",
    "        input_data = self.inputs\n",
    "        low_level_conv1 = Convolution_Layer(shape=[3, 3, 1, 64], stddev=0.1, value=0.1)\n",
    "        h = low_level_conv1.feed_forward(input_data=input_data, stride=[1, 2, 2, 1])\n",
    "\n",
    "        low_level_conv2 = Convolution_Layer(shape=[3, 3, 64, 128], stddev=0.1, value=0.1)\n",
    "        h = low_level_conv2.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
    "\n",
    "        low_level_conv3 = Convolution_Layer(shape=[3, 3, 128, 128], stddev=0.1, value=0.1)\n",
    "        h = low_level_conv3.feed_forward(input_data=h, stride=[1, 2, 2, 1])\n",
    "\n",
    "        low_level_conv4 = Convolution_Layer(shape=[3, 3, 128, 256], stddev=0.1, value=0.1)\n",
    "        h = low_level_conv4.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
    "\n",
    "        low_level_conv5 = Convolution_Layer(shape=[3, 3, 256, 256], stddev=0.1, value=0.1)\n",
    "        h = low_level_conv5.feed_forward(input_data=h, stride=[1, 2, 2, 1])\n",
    "\n",
    "        low_level_conv6 = Convolution_Layer(shape=[3, 3, 256, 512], stddev=0.1, value=0.1)\n",
    "        h = low_level_conv6.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
    "\n",
    "        mid_level_conv1 = Convolution_Layer(shape=[3, 3, 512, 512], stddev=0.1, value=0.1)\n",
    "        h1 = mid_level_conv1.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
    "\n",
    "        mid_level_conv2 = Convolution_Layer(shape=[3, 3, 512, 256], stddev=0.1, value=0.1)\n",
    "        h1 = mid_level_conv2.feed_forward(input_data=h1, stride=[1, 1, 1, 1])\n",
    "\n",
    "        global_level_conv1 = Convolution_Layer(shape=[3, 3, 512, 512], stddev=0.1, value=0.1)\n",
    "        h2 = global_level_conv1.feed_forward(input_data=h, stride=[1, 2, 2, 1])\n",
    "\n",
    "        global_level_conv2 = Convolution_Layer(shape=[3, 3, 512, 512], stddev=0.1, value=0.1)\n",
    "        h2 = global_level_conv2.feed_forward(input_data=h2, stride=[1, 1, 1, 1])\n",
    "\n",
    "        global_level_conv3 = Convolution_Layer(shape=[3, 3, 512, 512], stddev=0.1, value=0.1)\n",
    "        h2 = global_level_conv3.feed_forward(input_data=h2, stride=[1, 2, 2, 1])\n",
    "\n",
    "        global_level_conv4 = Convolution_Layer(shape=[3, 3, 512, 512], stddev=0.1, value=0.1)\n",
    "        h2 = global_level_conv4.feed_forward(input_data=h2, stride=[1, 1, 1, 1])\n",
    "\n",
    "        h2_flat = tf.reshape(h2, [BATCH_SIZE, -1])\n",
    "        dim = h2_flat.get_shape()[1].value\n",
    "        global_level_FC1 = FullyConnected_Layer(shape=[dim, 1024], stddev=0.04, value=0.1)\n",
    "        h2 = global_level_FC1.feed_forward(input_data=h2_flat)\n",
    "\n",
    "        global_level_FC2 = FullyConnected_Layer(shape=[1024, 512], stddev=0.04, value=0.1)\n",
    "        h2 = global_level_FC2.feed_forward(input_data=h2)\n",
    "\n",
    "        global_level_FC3 = FullyConnected_Layer(shape=[512, 256], stddev=0.04, value=0.1)\n",
    "        h2 = global_level_FC3.feed_forward(input_data=h2)\n",
    "\n",
    "        fusion_layer = Fusion_Layer(shape=[1, 1, 512, 256], stddev=0.1, value=0.1)\n",
    "        h = fusion_layer.feed_forward(h1, h2, stride=[1, 1, 1, 1])\n",
    "\n",
    "        colorization_level_conv1 = Convolution_Layer(shape=[3, 3, 256, 128], stddev=0.1, value=0.1)\n",
    "        h = colorization_level_conv1.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
    "\n",
    "        h = tf.image.resize_images(h, [56, 56], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        colorization_level_conv2 = Convolution_Layer(shape=[3, 3, 128, 64], stddev=0.1, value=0.1)\n",
    "        h = colorization_level_conv2.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
    "\n",
    "        colorization_level_conv3 = Convolution_Layer(shape=[3, 3, 64, 64], stddev=0.1, value=0.1)\n",
    "        h = colorization_level_conv3.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
    "\n",
    "        h = tf.image.resize_images(h, [112, 112], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        colorization_level_conv4 = Convolution_Layer(shape=[3, 3, 64, 32], stddev=0.1, value=0.1)\n",
    "        h = colorization_level_conv4.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
    "\n",
    "        output_layer = Output_Layer(shape=[3, 3, 32, 2], stddev=0.1, value=0.1)\n",
    "        logits = output_layer.feed_forward(input_data=h, stride=[1, 1, 1, 1])\n",
    "\n",
    "        self.output = tf.image.resize_images(logits, [224, 224], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        self.loss = tf.reduce_mean(tf.squared_difference(self.labels, self.output))\n",
    "        \n",
    "    def train(self, data, log):\n",
    "        optimizer = tf.train.AdamOptimizer(1e-4).minimize(self.loss)\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as session:\n",
    "            session.run(tf.global_variables_initializer())\n",
    "            print('All variables Initialized')\n",
    "            if USE_PRETRAINED:\n",
    "                saver.restore(session, os.path.join(MODEL_DIR, PRETRAINED))\n",
    "                print('Pretrained weights loaded')\n",
    "            for epoch in range (NUM_EPOCHS):\n",
    "                avg_cost = 0\n",
    "                data = DATA(dirname)\n",
    "                for batch in range(int(data.size/BATCH_SIZE)):\n",
    "                    batchX, batchY, _ = data.generate_batch()\n",
    "                    feed_dict = {self.inputs: batchX, self.labels: batchY}\n",
    "                    _, loss_val = session.run([optimizer, self.loss], feed_dict=feed_dict)\n",
    "                    print(\"batch:\", batch, \" loss: \", loss_val)\n",
    "                    avg_cost += loss_val / int(data.size/BATCH_SIZE)\n",
    "                print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.5f}\".format(avg_cost))\n",
    "                log.write(\"Epoch: \" + str(epoch + 1) + \" Average Cost: \" + str(avg_cost) + \"\\n\")\n",
    "\n",
    "            save_path = saver.save(session, os.path.join(MODEL_DIR, \"model\" + str(BATCH_SIZE) + \"_\" + str(NUM_EPOCHS) + \".ckpt\"))\n",
    "            print(\"Model saved in path: %s\" % save_path)\n",
    "            log.write(\"Model saved in path: \" + save_path + \"\\n\")\n",
    "\n",
    "    def test(self, data, log):\n",
    "        data = DATA(dirname)\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as session:\n",
    "            saver.restore(session, os.path.join(MODEL_DIR, \"model\" + str(BATCH_SIZE) + \"_\" + str(NUM_EPOCHS) + \".ckpt\"))\n",
    "            avg_cost = 0\n",
    "            total_batch = int(data.size/BATCH_SIZE)\n",
    "            for _ in range(total_batch):\n",
    "                batchX, batchY, filelist = data.generate_batch()\n",
    "                feed_dict = {self.inputs: batchX, self.labels: batchY}\n",
    "                predY, loss = session.run([self.output, self.loss], feed_dict=feed_dict)\n",
    "                reconstruct(deprocess(batchX), deprocess(predY), filelist)\n",
    "                avg_cost += loss/total_batch\n",
    "            print(\"cost =\", \"{:.3f}\".format(avg_cost))\n",
    "            log.write(\"Average Cost: \" + str(avg_cost) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Loaded\n",
      "Model Initialized\n",
      "Model Built\n",
      "All variables Initialized\n",
      "Epoch: 1 cost = 0.00000\n",
      "Epoch: 2 cost = 0.00000\n",
      "Epoch: 3 cost = 0.00000\n",
      "Epoch: 4 cost = 0.00000\n",
      "Epoch: 5 cost = 0.00000\n",
      "Epoch: 6 cost = 0.00000\n",
      "Epoch: 7 cost = 0.00000\n",
      "Epoch: 8 cost = 0.00000\n",
      "Epoch: 9 cost = 0.00000\n",
      "Epoch: 10 cost = 0.00000\n",
      "Epoch: 11 cost = 0.00000\n",
      "Epoch: 12 cost = 0.00000\n",
      "Epoch: 13 cost = 0.00000\n",
      "Epoch: 14 cost = 0.00000\n",
      "Epoch: 15 cost = 0.00000\n",
      "Epoch: 16 cost = 0.00000\n",
      "Epoch: 17 cost = 0.00000\n",
      "Epoch: 18 cost = 0.00000\n",
      "Epoch: 19 cost = 0.00000\n",
      "Epoch: 20 cost = 0.00000\n",
      "Epoch: 21 cost = 0.00000\n",
      "Epoch: 22 cost = 0.00000\n",
      "Epoch: 23 cost = 0.00000\n",
      "Epoch: 24 cost = 0.00000\n",
      "Epoch: 25 cost = 0.00000\n",
      "Epoch: 26 cost = 0.00000\n",
      "Epoch: 27 cost = 0.00000\n",
      "Epoch: 28 cost = 0.00000\n",
      "Epoch: 29 cost = 0.00000\n",
      "Epoch: 30 cost = 0.00000\n",
      "Epoch: 31 cost = 0.00000\n",
      "Epoch: 32 cost = 0.00000\n",
      "Epoch: 33 cost = 0.00000\n",
      "Epoch: 34 cost = 0.00000\n",
      "Epoch: 35 cost = 0.00000\n",
      "Epoch: 36 cost = 0.00000\n",
      "Epoch: 37 cost = 0.00000\n",
      "Epoch: 38 cost = 0.00000\n",
      "Epoch: 39 cost = 0.00000\n",
      "Epoch: 40 cost = 0.00000\n",
      "Epoch: 41 cost = 0.00000\n",
      "Epoch: 42 cost = 0.00000\n",
      "Epoch: 43 cost = 0.00000\n",
      "Epoch: 44 cost = 0.00000\n",
      "Epoch: 45 cost = 0.00000\n",
      "Epoch: 46 cost = 0.00000\n",
      "Epoch: 47 cost = 0.00000\n",
      "Epoch: 48 cost = 0.00000\n",
      "Epoch: 49 cost = 0.00000\n",
      "Epoch: 50 cost = 0.00000\n",
      "Epoch: 51 cost = 0.00000\n",
      "Epoch: 52 cost = 0.00000\n",
      "Epoch: 53 cost = 0.00000\n",
      "Epoch: 54 cost = 0.00000\n",
      "Epoch: 55 cost = 0.00000\n",
      "Epoch: 56 cost = 0.00000\n",
      "Epoch: 57 cost = 0.00000\n",
      "Epoch: 58 cost = 0.00000\n",
      "Epoch: 59 cost = 0.00000\n",
      "Epoch: 60 cost = 0.00000\n",
      "Epoch: 61 cost = 0.00000\n",
      "Epoch: 62 cost = 0.00000\n",
      "Epoch: 63 cost = 0.00000\n",
      "Epoch: 64 cost = 0.00000\n",
      "Epoch: 65 cost = 0.00000\n",
      "Epoch: 66 cost = 0.00000\n",
      "Epoch: 67 cost = 0.00000\n",
      "Epoch: 68 cost = 0.00000\n",
      "Epoch: 69 cost = 0.00000\n",
      "Epoch: 70 cost = 0.00000\n",
      "Epoch: 71 cost = 0.00000\n",
      "Epoch: 72 cost = 0.00000\n",
      "Epoch: 73 cost = 0.00000\n",
      "Epoch: 74 cost = 0.00000\n",
      "Epoch: 75 cost = 0.00000\n",
      "Epoch: 76 cost = 0.00000\n",
      "Epoch: 77 cost = 0.00000\n",
      "Epoch: 78 cost = 0.00000\n",
      "Epoch: 79 cost = 0.00000\n",
      "Epoch: 80 cost = 0.00000\n",
      "Epoch: 81 cost = 0.00000\n",
      "Epoch: 82 cost = 0.00000\n",
      "Epoch: 83 cost = 0.00000\n",
      "Epoch: 84 cost = 0.00000\n",
      "Epoch: 85 cost = 0.00000\n",
      "Epoch: 86 cost = 0.00000\n",
      "Epoch: 87 cost = 0.00000\n",
      "Epoch: 88 cost = 0.00000\n",
      "Epoch: 89 cost = 0.00000\n",
      "Epoch: 90 cost = 0.00000\n",
      "Epoch: 91 cost = 0.00000\n",
      "Epoch: 92 cost = 0.00000\n",
      "Epoch: 93 cost = 0.00000\n",
      "Epoch: 94 cost = 0.00000\n",
      "Epoch: 95 cost = 0.00000\n",
      "Epoch: 96 cost = 0.00000\n",
      "Epoch: 97 cost = 0.00000\n",
      "Epoch: 98 cost = 0.00000\n",
      "Epoch: 99 cost = 0.00000\n",
      "Epoch: 100 cost = 0.00000\n",
      "Model saved in path: E:\\PembelajaranMesinLab\\UAS\\Model/model1_100.ckpt\n",
      "Model Trained\n",
      "Test Data Loaded\n",
      "INFO:tensorflow:Restoring parameters from E:\\PembelajaranMesinLab\\UAS\\Model/model1_100.ckpt\n",
      "cost = 0.000\n",
      "Image Reconstruction Done\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with open(os.path.join(LOG_DIR, str(datetime.datetime.now().strftime(\"%Y%m%d\")) + \"_\" + str(BATCH_SIZE) + \"_\" + str(NUM_EPOCHS) + \".txt\"), \"w\") as log:\n",
    "        log.write(str(datetime.datetime.now()) + \"\\n\")\n",
    "        log.write(\"Use Pretrained Weights: \" + str(USE_PRETRAINED) + \"\\n\")\n",
    "        log.write(\"Pretrained Model: \" + PRETRAINED + \"\\n\")\n",
    "        # READ DATA\n",
    "        train_data = TRAIN_DIR\n",
    "        print(\"Train Data Loaded\")\n",
    "        # BUILD MODEL\n",
    "        model = MODEL()\n",
    "        print(\"Model Initialized\")\n",
    "        model.build()\n",
    "        print(\"Model Built\")\n",
    "        # TRAIN MODEL\n",
    "        model.train(train_data, log)\n",
    "        print(\"Model Trained\")\n",
    "        # TEST MODEL\n",
    "        test_data = TEST_DIR\n",
    "        print(\"Test Data Loaded\")\n",
    "        model.test(test_data, log)\n",
    "        print(\"Image Reconstruction Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
